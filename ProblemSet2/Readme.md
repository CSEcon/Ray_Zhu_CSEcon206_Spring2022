# Problem Set 2: Cooperative AI and the Future of Mechanism Design
> *Disclaimer: Submissions to Problem Set 2 for [COMPSCI/ECON 206 Computational Microeconomics](https://ce.pubpub.org/), 2022 Spring Term (Seven Week - Second) instructed by [Prof. Luyao Zhang](http://scholars.duke.edu/person/luyao.zhang) at Duke Kunshan University.*


## Author: Ray Zhu

## Class of 2022, Economics, Duke Kunshan Univesity

 
### Disclaimer: Submissions to Problem Set 2 for COMPSCI/ECON 206 Computational Microeconomics, 2022 Spring Term (Seven Week - Second) instructed by Prof. Luyao Zhang at Duke Kunshan University.


### RQ1: What is cooperative AI? What do you see as the potential that computer science and economics can jointly contribute to advance cooperative AI

Cooperation issues, in which agents seek ways to improve their well-being together, are common and significant (Dafoe et al 2020). As Dafoe et al. (2021) suggested, “to help humanity solve fundamental problems of cooperation, scientists need to reconceive artificial intelligence as deeply social” so that “machines” can “learn to find common ground”. Game theory is concerned with humans’ cooperation problems. But cooperative AI, making one step further, expands the consideration of AI and among AIs. It aims at perceiving different entities of AI as human beings and proposes some methods to help them cooperate toward a common goal and be consistent with humans’ goals and values. In a broad sense, I would say (and based on my understanding of Prof. Vincent’s lecture), cooperative AI is not only the business between an AI and another, instead, but it also studies the interaction between human and human, AI and AI, and AI and humans. We can treat AI as humans, but we can also view humans as some kind of AI, can’t we? 

I think the combination of economics and computer science can definitely benefit the advancement of cooperative AI. First, I think many of the cooperative AI problems are built up upon game theory and relevant models. Game theory, of course, is listed as a branch of economics and mathematics. We may engage the ideas in economics, such as utility, marginal cost, and even concepts in behavioral economics, to help analyze and solve the problems. However, as AI is built on top of computer science, we, of course, should introduce computer science knowledge to understand the difference between AI and human beings in traditional game theory. Besides, computer science gives us various tools to compute, simulate, and verify the results and validity of theoretical models.


### RQ2: Besides the desirable outcomes of cooperation, what other desirable outcomes the mechanism design theory aims at achieving?

To begin, another desirable consequence we wish to attain is AI alignment. AI alignment, or the creation of agents that act in accordance with human intents, preferences, and values, is a critical component of cooperative AI (Dafoe et al. 2021). The cooperation among machines is not enough: the goal of cooperative AI and mechanism design is to better serve social needs and higher productivity. Therefore, we need to design the system in a way that AI’s actions are consistent with humans’ real values and needs.

Besides, we hope to learn from machines’ cooperation as Prof. Vincent suggested that “studying how machines cooperate, some ways of getting to cooperation make sense for humans as well”. Mechanism design studies how to achieve a desirable outcome given the limitation of information asymmetry, interest conflict, and more. Although machines may work differently from human players in a game (machines are to be specified on their preferences and beliefs, and they have a more vague boundary), machines and humans, of course, would share some in common, and we can learn from cooperative AI and mechanism design to advance game theory among human beings (Conitzer 2019).

Moreover, desirable outcomes include contributions to the economics-wide applications, including taxation, public good provision, and even financial markets (Aziz 2010). An auction market is one example of how mechanism design theory can be used (“Mechanism Design Theory” n.d.). Regulators’ primary purpose is to ensure that the market is efficient and orderly for participants. To achieve this goal, several entities with varying levels of information and association are involved. The goal of mechanism design theory is to govern and control the information that market participants have access to in order to accomplish the desired outcome of a well-functioning market. This requires monitoring information and activity for exchanges, market makers, buyers, and sellers at multiple levels.


### RQ3: What are the limitations of the current mechanism design theory in achieving desirable outcomes? What new challenging are we facing in a new era with more and more human and AI interactions?

The first limitation is that cooperation or desirable results may not be reached when conditions change. As Prof. Vincent’s lecture suggested, game-theoretic failures to cooperate can happen even with almost perfectly aligned agents (I cannot find which of his paper emphasized this idea). But this limitation echoes with the Gibbard-Satterthwaite theorem, which states that some strategy incentives can only be attained under certain technical constraints and conditions (“The Gibbard-Satterthwaite Impossibility Theorem” 2014). In other words, conditions or environments limit the current mechanism design theory in achieving desirable outcomes.

The second limitation lies in the sources, information, and materials that help make the mechanism design. According to Dafoe et al. (2020), “the vast majority of reinforcement learning models are trained in simulator environments due to safety concerns”. Unfortunately, in these specific environments, human data is typically very limited. Therefore, as a result, an accurate estimation of human policies is challenging. Among the several factors we typically consider in game thoery and mechanism design, information is definitely one of the most important and sensitive factors. The information we collect, how we approach the information, and how we apply the information and its features (e.g., symmetry) will all play a role in the effectiveness of mechanism design.

### RQ4: What new challenging are we facing in a new era with more and more human and AI interactions?

We may face coercion problems. Many unique features that are good for collaboration may also be useful for coercion, which is defined as an actor's attempt to obtain something from another by threatening or using force. Increases in coercive competency that are arbitrary are not often regarded as socially desirable since they may result in an (undeserved) transfer of value from others to the more coercively competent actor, exposing society to harms, threats, and (illegitimate) uses of force (Dafoe et al. 2020). They may also lead to increased use of coercion, which is often viewed as unpleasant. Cooperation, on the other hand, entails welfare gains among the cooperative set, whereas coercion cannot guarantee anything.

Moreover, another concern that Prof. Vincent brought up in the lecture is repeated game models, which I believe are relevant to the scenario when there are more and more human and AI interactions. Because in a simple and traditional game that only engages human beings, we consider repeated models when players play the game a lot of times. The results also differ when repeating for 100 times, 1000 times, and infinite times (Aumann 1985). Now, similarly, when more and more human and AI interactions exist, the variations and complexity of the game do come from not only the increasing number of participants but also the repeating times. 

### RQ5: Based on your interest and your advantage in skills, how do you plan to contribute to overcoming the limitations of the current mechanism design theory in achieving desirable outcomes and making this world a better place?

First and foremost, I am a student of economics. I can continue to study economics and conduct research on game theory and mechanism design in order to achieve desired outcomes. From an economics standpoint, we may apply the mechanism design theory to more cases in order to identify its limits and increase its applicability. Furthermore, when I work in the industry in the future, I will seek more opportunities to evaluate the validity of mechanism design theory. When theories are put into practice, I feel they are useful and significant. By incorporating mechanism design into practical or professional projects, we will be able to reflect on and improve the theory, as well as add new information. Because we will apply mechanism theory in diverse settings and enhance the theory, all of the foregoing may provide a solution to the first limitation I described in RQ3.

Second, I would advocate for blockchain in the case of a lack of information or access to information. Due to its incentive system, blockchain allows a decentralized network to document and distribute information, and it can collect more comprehensive information in a fair, efficient, and compelling manner without worrying about trust and data reliability. Mechanism designers would be able to make greater use of the knowledge and come up with better design solutions using it.


### References

Aumann, Robert J. 1985. “Repeated Games.” Issues in Contemporary Microeconomics and Welfare, 209–42. https://doi.org/10.1007/978-1-349-06876-0_5.
Aziz, Haris. 2010. “Multiagent Systems.” ACM SIGACT News 41 (1): 34. https://doi.org/10.1145/1753171.1753181.
Conitzer, Vincent. 2019. “Designing Preferences, Beliefs, and Identities for Artificial Intelligence.” Proceedings of the AAAI Conference on Artificial Intelligence 33 (July): 9755–59. https://doi.org/10.1609/aaai.v33i01.33019755.
Dafoe, Allan, Yoram Bachrach, Gillian Hadfield, Eric Horvitz, Kate Larson, and Thore Graepel. 2021. “Cooperative AI: Machines Must Learn to Find Common Ground.” Nature 593 (7857): 33–36. https://doi.org/10.1038/d41586-021-01170-0.
Dafoe, Allan, Edward Hughes, Yoram Bachrach, Tantum Collins, Kevin R. McKee, Joel Z. Leibo, Kate Larson, and Thore Graepel. 2020. “Open Problems in Cooperative AI.” ArXiv:2012.08630 [Cs], December. https://arxiv.org/abs/2012.08630.
“Mechanism Design Theory.” n.d. Investopedia. Accessed April 22, 2022. https://www.investopedia.com/terms/m/mechanism-design-theory.asp#:~:text=Mechanism%20design%20takes%20private%20information.
“The Gibbard-Satterthwaite Impossibility Theorem.” 2014. Game Theory and Mechanism Design, March, 249–65. https://doi.org/10.1142/9789814525053_0017.
