# Ray_Zhu_CSEcon206_Spring2022

# Problem Set 2: Cooperative AI and the Future of Mechanism Design

## Author: Ray Zhu

## Class of 2022, Economics, Duke Kunshan Univesity

 
## Disclaimer: Submissions to Problem Set 2 for COMPSCI/ECON 206 Computational Microeconomics, 2022 Spring Term (Seven Week - Second) instructed by Prof. Luyao Zhang at Duke Kunshan University.



RQ1: What is cooperative AI? What do you see as the potential that computer science and economics can jointly contribute to advance cooperative AI

Problems of cooperation--in which agents seek ways to jointly improve their welfare--are ubiquitous and important Dafoe et al (2020). As Dafoe et al. (2021) suggested, “to help humanity solve fundamental problems of cooperation, scientists need to reconceive artificial intelligence as deeply social” so that “machines” can “learn to find common ground”. Game theory is concerned with humans’ cooperation problems. But cooperative AI, making one step further, expands the consideration of AI and among AIs. It aims at perceiving different entities of AI as human beings and proposes some methods to help them cooperate toward a common goal and be consistent with humans’ goals and values. In a broad sense, I would say (and based on my understanding of Prof. Vince’s lecture), cooperative AI is not only the business between an AI and another, instead, but it also studies the interaction between human and human, AI and AI, and AI and humans. We can treat AI as humans, but we can also view humans as some kind of AI, can’t we? I think the combination of economics and computer science can definitely benefit the advancement of cooperative AI. First, I think many of the cooperative AI problems are built up upon game theory and relevant models. Game theory, of course, is listed as a branch of economics and mathematics. We may engage the ideas in economics, such as utility, marginal cost, and even concepts in behavioral economics to help analyze and solve the problems. However, as AI is built on top of computer science, we of course should introduce computer science knowledge to understand the difference between AI and human beings in traditional game theory. Besides, computer science gives us various tools to compute, simulate, and verify the results and validity of theoretical models.


RQ2: Besides the desirable outcomes of cooperation, what other desirable outcomes the mechanism design theory aims at achieving?

1. AI alignment is another desirable outcome we want to achieve. The design of agents that will act in accordance with human intentions, preferences, and values — known as AI alignment — is a crucial part of cooperative AI (Dafoe et al. 2021).

2. We hope to learn from machines’ cooperation as Prof. Vince suggested that “studying how machines cooperate, some ways of getting to cooperation make sense for humans as well”.

3. Other desirable outcomes may include contributions to the economics-wide applications, including taxation, public good provision, and more (Aziz 2010).


3. What are the limitations of the current mechanism design theory in achieving desirable outcomes? What new challenging are we facing in a new era with more and more human and AI interactions?

1. As Prof. Vince’s lecture suggested, game-theoretic failures to cooperate can happen even with almost perfectly aligned agents. 

2. Besides, due to safety concerns, the vast majority of reinforcement learning models are trained using simulator environments (Dafoe et al 2020). Unfortunately, in these environments, human data is typically very limited and, as a result, an accurate estimation of human policies is challenging. 

3. Another concern that Prof. Vince brought up in the lecture is repeated game models, which I believe are relevant to the scenario where there are more and more human and AI interactions. 


References

Aziz, Haris. 2010. “Multiagent Systems.” ACM SIGACT News 41 (1): 34. https://doi.org/10.1145/1753171.1753181.

Dafoe, Allan, Yoram Bachrach, Gillian Hadfield, Eric Horvitz, Kate Larson, and Thore Graepel. 2021. “Cooperative AI: Machines Must Learn to Find Common Ground.” Nature 593 (7857): 33–36. https://doi.org/10.1038/d41586-021-01170-0.

Dafoe, Allan, Edward Hughes, Yoram Bachrach, Tantum Collins, Kevin R. McKee, Joel Z. Leibo, Kate Larson, and Thore Graepel. 2020. “Open Problems in Cooperative AI.” ArXiv:2012.08630 [Cs], December. https://arxiv.org/abs/2012.08630.
